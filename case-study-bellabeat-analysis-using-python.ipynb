{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# INTRODUCTION\n\nCapstone Project: **Google Data Analytics Professional Certificate** \n\nGoal: The **6 steps of Data Analysis**\n\nTitle: Bellabeat: How Can A Wellness Technology Company Play It Smart?\n\nAuthor: Josh Chen\n\nDate: 26 March 2021\n\n***\n\n# STEP 1: ASK\n\n## 1.0 Background\n1.0.1 Bellabeat is a high-tech manufacturer of health-focused products for women.\n\n1.0.2 Bellabeat's product is smart decices with users' data.\n\n## 1.1 Business Task:\n1.1.1 Analyze FitBit Fitness Tracker Data \n\n1.1.2 Gain insights into how consumers are using the FitBit app \n\n1.1.3 Discover trends and insights for Bellabeat marketing strategy\n\n## 1.2 Business Objectives:  \n1.2.1 What are the trends identified?\n\n1.2.2 How could these trends apply to Bellabeat customers?\n\n1.2.3 How could these trends help influence Bellabeat marketing strategy?\n\n## 1.3 Deliverables:\n1.3.1 A clear summary of the business task\n\n1.3.2 A description of all data sources used\n\n1.3.3 Documentation of any cleaning or manipulation of data\n\n1.3.4 A summary of analysis\n\n1.3.5 Supporting visualizations and key findings\n\n1.3.6 High-level content recommendations based on the analysis\n\n## 1.4 Key Stakeholders:\n1.4.1 Urška Sršen: Bellabeat’s cofounder and Chief Creative Officer\n\n1.4.2 Sando Mur: Mathematician, Bellabeat’s cofounder and key member of the Bellabeat executive team\n\n1.4.3 Bellabeat marketing analytics team: A team of data analysts guiding Bellabeat's marketing strategy.\n\n\n***\n\n\n# STEP 2: PREPARE\n\n## 2.1 Information on Data Source:\n1. The data is public available on [Kaggle: FitBit Fitness Tracker Data](https://www.kaggle.com/arashnic/fitbit) and stored in 18 csv files. \n2. Generated by respondents from a distributed survey via Amazon Mechanical Turk between 12 March 2016 to 12 May 2016.\n3. FitBit users consented to the submission of personal tracker data.\n4. Data collected includes: (1) physical activity recorded in minutes; (2) heart rate; (3) sleep monitoring; (4) daily activity; (5) steps.\n\n## 2.2 Is Data ROCCC?\nA good data source is ROCCC which stands for **R**eliable, **O**riginal, **C**omprehensive, **C**urrent, and **C**ited.\n1. Reliable: LOW - Not reliable as it only has 30 respondents\n2. Original: LOW - Third party provider (Amazon Mechanical Turk)\n3. Comprehensive: MED - Parameters match most of Bellabeat's products' parameters\n4. Current: LOW - Data is obsolete or relevant\n5. Cited: High - Furberg, R., Brinton, J., Keating, M., & Ortiz, A. (2016) \n\nAlthough the dataset is not good enough to produce business recommendations, it is still good enough to practice.\n\n\n#### 2.3 Data Selection:\n```\n    • dailyActivity_merged.csv\n```\n\n\n***","metadata":{"_uuid":"fea909ec-c82f-4971-9070-fcc02961a32c","_cell_guid":"feeabaef-2405-4000-912d-19ab6a3018f8","execution":{"iopub.status.busy":"2021-05-22T15:44:51.577765Z","iopub.execute_input":"2021-05-22T15:44:51.57837Z","iopub.status.idle":"2021-05-22T15:44:51.592943Z","shell.execute_reply.started":"2021-05-22T15:44:51.578239Z","shell.execute_reply":"2021-05-22T15:44:51.591483Z"}}},{"cell_type":"markdown","source":"# STEP 3: PROCESS\n\n## 3.1 Preparing the Environment\n\nThe ```numPy, pandas, matplotlib, datetime``` packages are installed and aliased for easy reading.","metadata":{"_uuid":"07d219e0-c65f-478c-9734-cb6cdc62a992","_cell_guid":"38859931-1e88-4365-9514-3ba368222cb5","trusted":true}},{"cell_type":"code","source":"# import packages and alias\nimport numpy as np # data arrays\nimport pandas as pd # data structure and data analysis\nimport matplotlib as plt # data visualization\nimport datetime as dt # date time","metadata":{"_uuid":"27e4f97b-1e17-462c-9cfe-d044b42cc1a7","_cell_guid":"53bedab9-16e6-459a-b3ce-e0c6449b246f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-21T08:07:09.669131Z","iopub.execute_input":"2022-04-21T08:07:09.669625Z","iopub.status.idle":"2022-04-21T08:07:09.680348Z","shell.execute_reply.started":"2022-04-21T08:07:09.669507Z","shell.execute_reply":"2022-04-21T08:07:09.679287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Importing data set\nReading in the selected file.","metadata":{"_uuid":"ac279df1-646a-43ba-9f30-36fe2b154e66","_cell_guid":"41fc2d38-ee2b-4093-af09-c9d5b40b3ad1","trusted":true}},{"cell_type":"code","source":"# read_csv function to read the required CSV file\ndaily_activity = pd.read_csv(\"../input/fitbit/Fitabase Data 4.12.16-5.12.16/dailyActivity_merged.csv\")","metadata":{"_uuid":"c67360eb-49d0-4d8c-b436-ae473e3c7623","_cell_guid":"7b95c099-c3e8-46f8-b60b-cbfaac7c3cd2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-21T08:07:09.682263Z","iopub.execute_input":"2022-04-21T08:07:09.682749Z","iopub.status.idle":"2022-04-21T08:07:09.716604Z","shell.execute_reply.started":"2022-04-21T08:07:09.682699Z","shell.execute_reply":"2022-04-21T08:07:09.715744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Data cleaning and manipulation\n\n### 3.3.1 Steps\n\n#### 1. Observe and familiarize with data: previewing using head function to show the first 10 rows of daily_activity to familiarise with the data.","metadata":{"_uuid":"23415393-9f2d-48ff-9cf7-9b56d0b9d2fc","_cell_guid":"7d80d7cf-e7f6-4951-9a8d-ec20258a2f2f","trusted":true}},{"cell_type":"code","source":"# preview first 10 rows with all columns\ndaily_activity.head(10)","metadata":{"_uuid":"941abfee-ce91-435a-9a7f-22e129b45d30","_cell_guid":"4126117c-5d8d-47f5-be26-ad0ef695ec29","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-21T08:07:09.718464Z","iopub.execute_input":"2022-04-21T08:07:09.719125Z","iopub.status.idle":"2022-04-21T08:07:09.765609Z","shell.execute_reply.started":"2022-04-21T08:07:09.719074Z","shell.execute_reply":"2022-04-21T08:07:09.764541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Check for null or missing values: finding out whether there is any null or missing values in daily_activity.","metadata":{}},{"cell_type":"code","source":"# obtain the # of missing data points per column\nmissing_values_count = daily_activity.isnull().sum()\n\n# look at the # of missing points in all columns\nmissing_values_count[:]","metadata":{"_uuid":"29266e28-766a-41e4-bd3f-1c945baea3bb","_cell_guid":"af5c7249-a592-4e10-bacd-4188ce32fabc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-21T08:07:09.767120Z","iopub.execute_input":"2022-04-21T08:07:09.767426Z","iopub.status.idle":"2022-04-21T08:07:09.777462Z","shell.execute_reply.started":"2022-04-21T08:07:09.767395Z","shell.execute_reply":"2022-04-21T08:07:09.776752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. Perform sanity check of data: finding out the basic information of daily_activity:\n* no. of rows and columns\n* name of columns\n* type of value\n* counting the unique ID","metadata":{}},{"cell_type":"code","source":"# show basic information of data\ndaily_activity.info()\n\n# count distinct value of \"Id\"\nunique_id = len(pd.unique(daily_activity[\"Id\"]))\n  \nprint(\"# of unique Id: \" + str(unique_id))","metadata":{"_uuid":"a611da02-43f1-4e0c-ab2a-1f1a648a329d","_cell_guid":"72b6f724-a60c-4e0d-b627-e1bfdc7ed820","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-21T08:07:09.778813Z","iopub.execute_input":"2022-04-21T08:07:09.779290Z","iopub.status.idle":"2022-04-21T08:07:09.815226Z","shell.execute_reply.started":"2022-04-21T08:07:09.779256Z","shell.execute_reply":"2022-04-21T08:07:09.814358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3.2 Observations\n\nFrom the above observation, noted that\n\n1. There is no Null or missing values.\n\n2. Data frame has 940 rows and 15 columns.\n\n3. ActivityDate is wrongly classified as object dtype and has to be converted to datetime64 dtype.\n\n4. There are 33 unique IDs.","metadata":{"_uuid":"ba96fa39-7a49-43d3-a056-9e6d7c4da0be","_cell_guid":"8af44964-74a0-4d17-88e9-ec09bcec6277","trusted":true}},{"cell_type":"markdown","source":"### 3.3.3 Manipulation\n\n#### 1. Let's convert ActivityDate to datatime64 dtype and convert format of ActivityDate to yyyy-mm-dd. Then, printing head 5 rows could confirm whether this outcome is as same as our expectation.","metadata":{"_uuid":"8916b38a-020a-476a-a3b8-dcff57614da0","_cell_guid":"220e6c03-37de-42e4-ac9b-47ade59e2af6","trusted":true}},{"cell_type":"code","source":"# convert \"ActivityDate\" to datatime64 dtype and format to yyyy-mm-dd\ndaily_activity[\"ActivityDate\"] = pd.to_datetime(daily_activity[\"ActivityDate\"], format=\"%m/%d/%Y\")\n\n# re-print information to confirm\ndaily_activity.info()\n\n# print the first 5 rows of \"ActivityDate\" to confirm\ndaily_activity[\"ActivityDate\"].head()","metadata":{"_uuid":"29173d13-4135-4e6c-a37c-b833567073f7","_cell_guid":"10e0ae12-c842-4406-919d-ca947104d771","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-21T08:07:09.816818Z","iopub.execute_input":"2022-04-21T08:07:09.817344Z","iopub.status.idle":"2022-04-21T08:07:09.844692Z","shell.execute_reply.started":"2022-04-21T08:07:09.817309Z","shell.execute_reply":"2022-04-21T08:07:09.843523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Create new column DayOfTheWeek by separating the date into day of the week for further analysis, such Monday, Tuesday etc..","metadata":{}},{"cell_type":"code","source":"#r create new list of rearranged columns\nnew_cols = ['Id', 'ActivityDate', 'DayOfTheWeek', 'TotalSteps', 'TotalDistance', 'TrackerDistance', 'LoggedActivitiesDistance', 'VeryActiveDistance', 'ModeratelyActiveDistance', 'LightActiveDistance', 'SedentaryActiveDistance', 'VeryActiveMinutes', 'FairlyActiveMinutes', 'LightlyActiveMinutes', 'SedentaryMinutes', 'TotalExerciseMinutes', 'TotalExerciseHours', 'Calories']\n\n# reindex function to rearrange columns based on \"new_cols\"\ndf_activity = daily_activity.reindex(columns=new_cols)\n\n# print 1st 5 rows to confirm\ndf_activity.head(5)\n\n# create new column \"day_of_the_week\" to represent day of the week \ndf_activity[\"DayOfTheWeek\"] = df_activity[\"ActivityDate\"].dt.day_name()\n\n# print 1st 5 rows to confirm\ndf_activity[\"DayOfTheWeek\"].head(5)\n\n#Rearranging and renaming columns from ```XxxYyy``` to ```xxx_yyy```\n# rename columns\ndf_activity.rename(columns = {\"Id\":\"id\", \"ActivityDate\":\"date\", \"DayOfTheWeek\":\"day_of_the_week\", \"TotalSteps\":\"total_steps\", \"TotalDistance\":\"total_dist\", \"TrackerDistance\":\"track_dist\", \"LoggedActivitiesDistance\":\"logged_dist\", \"VeryActiveDistance\":\"very_active_dist\", \"ModeratelyActiveDistance\":\"moderate_active_dist\", \"LightActiveDistance\":\"light_active_dist\", \"SedentaryActiveDistance\":\"sedentary_active_dist\", \"VeryActiveMinutes\":\"very_active_mins\", \"FairlyActiveMinutes\":\"fairly_active_mins\", \"LightlyActiveMinutes\":\"lightly_active_mins\", \"SedentaryMinutes\":\"sedentary_mins\", \"TotalExerciseMinutes\":\"total_mins\",\"TotalExerciseHours\":\"total_hours\",\"Calories\":\"calories\"}, inplace = True)\n\n# print column names to confirm\nprint(df_activity.columns.values)\ndf_activity.head(5)","metadata":{"_uuid":"4032a725-60b2-4432-a496-8f89ca67e2e7","_cell_guid":"24767d8e-4b12-4da5-8534-46e48373a946","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-21T08:07:09.846319Z","iopub.execute_input":"2022-04-21T08:07:09.846662Z","iopub.status.idle":"2022-04-21T08:07:09.885957Z","shell.execute_reply.started":"2022-04-21T08:07:09.846628Z","shell.execute_reply":"2022-04-21T08:07:09.884915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. Let's create new column TotalMins being the sum of VeryActiveMinutes, FairlyActiveMinutes, LightlyActiveMinutes and SedentaryMinutes","metadata":{}},{"cell_type":"code","source":"# create new column \"total_mins\" containing sum of total minutes.\ndf_activity[\"total_mins\"] = df_activity[\"very_active_mins\"] + df_activity[\"fairly_active_mins\"] + df_activity[\"lightly_active_mins\"] + df_activity[\"sedentary_mins\"]\ndf_activity[\"total_mins\"].head(5)","metadata":{"_uuid":"8b542b7a-5f83-4404-bcdb-f38ee25a3227","_cell_guid":"b4ce574a-e7fa-4743-abe4-838540fa29ce","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-21T08:07:09.887784Z","iopub.execute_input":"2022-04-21T08:07:09.888510Z","iopub.status.idle":"2022-04-21T08:07:09.917835Z","shell.execute_reply.started":"2022-04-21T08:07:09.888458Z","shell.execute_reply":"2022-04-21T08:07:09.916171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4. Create new column TotalHours by converting new column in #4 to number of hours.","metadata":{}},{"cell_type":"code","source":"# create new column *total_hours* by converting to hour and round float to two decimal places\ndf_activity[\"total_hours\"] = round(df_activity[\"total_mins\"] / 60)\n\n# print 1st 5 rows to confirm\ndf_activity[\"total_hours\"].head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:09.919659Z","iopub.execute_input":"2022-04-21T08:07:09.920240Z","iopub.status.idle":"2022-04-21T08:07:09.930290Z","shell.execute_reply.started":"2022-04-21T08:07:09.920200Z","shell.execute_reply":"2022-04-21T08:07:09.928985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3.4 After data cleaning and manipulation, it is now ready to be analysed.","metadata":{}},{"cell_type":"markdown","source":"# STEP 4: ANALYZE\n\n## 4.1 Statistical analysis\n\nPulling the statistics of df_activity for analysis:\n* count - no. of rows\n* mean (average)\n* std (standard deviation)\n* min and max\n* percentiles 25%, 50%, 75%","metadata":{}},{"cell_type":"code","source":"# pull general statistics\ndf_activity.describe()","metadata":{"_uuid":"5a0f8f34-8675-483a-9255-16fbdd8d5f0d","_cell_guid":"540e3ee4-f56d-4979-a483-6e2deebc3fd0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-21T08:07:09.932955Z","iopub.execute_input":"2022-04-21T08:07:09.933664Z","iopub.status.idle":"2022-04-21T08:07:10.016321Z","shell.execute_reply.started":"2022-04-21T08:07:09.933609Z","shell.execute_reply":"2022-04-21T08:07:10.015382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interpreting statistical findings:\n\n1. On average, users logged 7,638 steps or 5.5km. However, recommended by CDC, an adult female has to take at least 10,000 steps or 8km per day to benefit their health, weight loss and fitness improvement. [Source: Medical News Today article](https://www.medicalnewstoday.com/articles/how-many-steps-should-you-take-a-day)\n\n2.  Sedentary users logged on average 991 minutes or 20 hours(85% of daytime).\n\n3. Average calories burned is 2,303 calories equivalent to 0.6 pound. (If we have more users' infomation such as the age, weight, daily tasks, exercise, hormones and daily calorie intake, we could provide them some advices to raise daily calories burned. [Source: Health Line article](https://www.healthline.com/health/fitness-exercise/how-many-calories-do-i-burn-a-day#Burning-calories))\n\n***\n\n","metadata":{}},{"cell_type":"markdown","source":"## 4.2 Users' Weekly Routine\nCreating a new dataset to group steps by each one day.","metadata":{}},{"cell_type":"code","source":"#First, we will order the dataset by the specified vector. This is because in default R arranges by alphabet\nday_list = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\ndf_activity['day_of_the_week'] = pd.Categorical(df_activity['day_of_the_week'], categories=day_list, ordered=True)\ndf_activity = df_activity.sort_values('day_of_the_week')\n\n#Then we create the new dataset\nday_steps_distance_sleep_calories = pd.pivot_table(df_activity,\n                                                   values=['total_steps','total_dist','calories','sedentary_mins'],\n                                                   index=['day_of_the_week'],\n                                                   aggfunc=np.mean\n                                                   )\nday_steps_distance_sleep_calories = day_steps_distance_sleep_calories.rename(columns={'total_steps':'avg_steps', 'total_dist':'avg_distance', 'calories':'avg_calories', 'sedentary_mins':'avg_sed_mins'})\nday_steps_distance_sleep_calories.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:10.017797Z","iopub.execute_input":"2022-04-21T08:07:10.018603Z","iopub.status.idle":"2022-04-21T08:07:10.058641Z","shell.execute_reply.started":"2022-04-21T08:07:10.018505Z","shell.execute_reply":"2022-04-21T08:07:10.057457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interpreting weekly routine findings:\n\n1. Users performance on Sunday is not better than on the midweek. Therefore, we suggest users work out every day, not on the weekend.\n\n2. The performance on Monday, Tuesday and Saturday is better than average. So, more steps help relieve the blue-Monday-anxiety.","metadata":{}},{"cell_type":"markdown","source":"# STEP 5: SHARE - Data Visualisation and Findings\n\nIn this step, we are creating visualizations and offering our findings based on our analysis.\n\n## 5.1 Frequency of usage across the week\n\nAlthough days in the week are continous, we have manipulated and transformed to categorical variables, like Monday, Tuesday etc.. So, we decided to use bar chart instead of histogram.\n\nIn this bar chart, we are looking at the frequency of FitBit app usage in each days of the week. \n\n1. Users prefer to track their activity on the app from Tuesday to Friday. \n\n2. The frequency dropped on Friday until next Monday. ","metadata":{}},{"cell_type":"code","source":"# import matplotlib package\nimport matplotlib.pyplot as plt\n\n# plotting bar chart\nplt.style.use(\"seaborn-darkgrid\")\nplt.figure(figsize=(8,4)) # specify size of the chart\n\ndf_activity_gp = df_activity.groupby(\"day_of_the_week\")\nday_of_the_week_cnt = df_activity_gp[\"day_of_the_week\"].count()\nplt.bar(day_list, day_of_the_week_cnt, color = \"lightskyblue\", edgecolor = \"black\")\n\n# adding annotations and visuals\nplt.xlabel(\"Day of the week\")\nplt.ylabel(\"Frequency\")\nplt.title(\"No. of times users logged in app across the week\")\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:10.061465Z","iopub.execute_input":"2022-04-21T08:07:10.061983Z","iopub.status.idle":"2022-04-21T08:07:10.276858Z","shell.execute_reply.started":"2022-04-21T08:07:10.061949Z","shell.execute_reply":"2022-04-21T08:07:10.275687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Calories burned\n\n### 5.2.1 Every steps taken by users\n\nIn this scatter plot, we can find the correlation between specific variables. We discovered that:\n\n1. It is a positive correlation. \n\n2. Outliers:\n    - Zero steps with zero calories burned: it means user did not use this product, not the trade-off.\n    - 1 observation of > 35,000 steps with < 3,000 calories burned.","metadata":{}},{"cell_type":"code","source":"# import matplotlib package\nimport matplotlib.pyplot as plt\n\n# plotting scatter plot\nplt.style.use(\"dark_background\")\nplt.figure(figsize=(8,6)) # specify size of the chart\nplt.scatter(df_activity.total_steps, df_activity.calories, \n            alpha = 0.8, c = df_activity.calories, \n            cmap = \"Spectral\")\n\n# add annotations and visuals\nmedian_calories = 2303\nmedian_steps = 7637\n\nplt.colorbar(orientation = \"vertical\")\nplt.axvline(median_steps, color = \"Blue\", label = \"Median steps: 7637\")\nplt.axhline(median_calories, color = \"Red\", label = \"Median calories burned: 2303\")\nplt.xlabel(\"Steps taken\")\nplt.ylabel(\"Calories burned\")\nplt.title(\"Calories burned for every step taken\")\nplt.grid(True)\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:10.278336Z","iopub.execute_input":"2022-04-21T08:07:10.278690Z","iopub.status.idle":"2022-04-21T08:07:10.671541Z","shell.execute_reply.started":"2022-04-21T08:07:10.278657Z","shell.execute_reply":"2022-04-21T08:07:10.670711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2.2 Every hour logged by users\n\nThe scatter plot is showing:\n\n1. A weak positive correlation shows that the increase of hours logged does not guarantee to more calories being burned. The reanson probably is that the average sedentary hours (purple line) are about 16 to 17 hours more. \n\n2. Outliers:\n   - The same zero value outliers\n   - An unusual red dot at the 24 hours with zero calorie burned.","metadata":{}},{"cell_type":"code","source":"# import matplotlib package\nimport matplotlib.pyplot as plt\n\n# plotting scatter plot\nplt.style.use(\"dark_background\")\nplt.figure(figsize=(8,6)) # Specify size of the chart\nplt.scatter(df_activity.total_hours, df_activity.calories, \n            alpha = 0.8, c = df_activity.calories, \n            cmap = \"Spectral\")\n\n# adding annotations and visuals\nmedian_calories = 2303\nmedian_hours = 20\nmedian_sedentary = 991 / 60\n\nplt.colorbar(orientation = \"vertical\")\nplt.axvline(median_hours, color = \"Blue\", label = \"Median steps: 2303\")\nplt.axvline(median_sedentary, color = \"Purple\", label = \"Median sedentary: 991/60\")\nplt.axhline(median_calories, color = \"Red\", label = \"Median hours: 20\")\nplt.xlabel(\"Hours logged\")\nplt.ylabel(\"Calories burned\")\nplt.title(\"Calories burned for every hour logged\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:10.674262Z","iopub.execute_input":"2022-04-21T08:07:10.674731Z","iopub.status.idle":"2022-04-21T08:07:11.043110Z","shell.execute_reply.started":"2022-04-21T08:07:10.674678Z","shell.execute_reply":"2022-04-21T08:07:11.041904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2.3 Percentage of Activity in Minutes\n\nThere are some findings in this pie chart:\n\n1. Sedentary minutes takes the biggest part at 81.3%. This indicates that users are using the FitBit app to record every daily activities such as daily commute, inactive movements (moving from one spot to another) etc.. \n\n2. Devices/APP is seldom being used to track fitness (ie. running); that is, the minor percentage of fairly active activity (1.1%) and very active activity (1.7%) are logged. This is a challenge for FitBit to APP design: if APP is a life recorder, FitBit can not fullfill the goal of increase users' fitness time; if APP is a fitness coach, FitBit probably help users increase fitness time.","metadata":{}},{"cell_type":"code","source":"# import packages\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# calculating total of individual minutes column\nvery_active_mins = df_activity[\"very_active_mins\"].sum()\nfairly_active_mins = df_activity[\"fairly_active_mins\"].sum()\nlightly_active_mins = df_activity[\"lightly_active_mins\"].sum()\nsedentary_mins = df_activity[\"sedentary_mins\"].sum()\n\n# plotting pie chart\nslices = [very_active_mins, fairly_active_mins, lightly_active_mins, sedentary_mins]\nlabels = [\"Very active minutes\", \"Fairly active minutes\", \"Lightly active minutes\", \"Sedentary minutes\"]\ncolours = [\"lightcoral\", \"yellowgreen\", \"lightskyblue\", \"darkorange\"]\nexplode = [0, 0, 0, 0.1]\nplt.style.use(\"default\")\nplt.pie(slices, labels = labels, \n        colors = colours, wedgeprops = {\"edgecolor\": \"black\"}, \n        explode = explode, autopct = \"%1.1f%%\")\nplt.title(\"Percentage of Activity in Minutes\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:07:11.044993Z","iopub.execute_input":"2022-04-21T08:07:11.045447Z","iopub.status.idle":"2022-04-21T08:07:11.288592Z","shell.execute_reply.started":"2022-04-21T08:07:11.045399Z","shell.execute_reply":"2022-04-21T08:07:11.287290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# STEP 6: ACT\n\nIn the final step, we will deliver our insights and provid recommendations based on our analysis. \n \n**1. What are the trends identified?**\n\n* Majority activities logged on the FitBit app is sedentary activities(85% of daytime). That is, health habits are still not \"habit\".\n\n* Users usually track their activities less on Sunday - perhaps because they still have the \"habit\" that fitness is a \"job\" and they need a day-off for fitness. \n\n**2. How could these trends apply to Bellabeat customers?**\n\n* Just a smart device or recording APP is far from enough to help users increase fitness time. The users usually expect to buy a smart device to have a perfect health life(including me). Therefore, Bellabeat should not only provid correct and useful infomation about users' health, habit and fitness data, but also instruct them how to do excercises.\n\n**3. How could these trends help influence Bellabeat marketing strategy?**\n\n* Bellabeat marketing team should tell potential customers that they are fitness coach and expert. For example, if users wear the devices in the gym, the APP can tell them how to and how much they should take exercises; after working out, APP can recommend some restaurants to have healthy meals near to their home.\n\n* On Sunday, Bellabeat app can show prompt notification to recommend some 10 minutes Youtube Yoga exercises.\n\n* Bellabeat marketing strategy should focus on providing a smart service, not a smart device/APP.\n\n\n***\n\n","metadata":{}}]}